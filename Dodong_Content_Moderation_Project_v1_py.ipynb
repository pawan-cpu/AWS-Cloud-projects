{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pawan-cpu/AWS-Cloud-projects/blob/main/Dodong_Content_Moderation_Project_v1_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dc3dzDzkNxM"
      },
      "source": [
        "# Project 1: Content Moderation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2USdj0Fcp1PA"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZkuR4JIp122"
      },
      "source": [
        "### Context\n",
        "\n",
        "The probability of the placement depends on various factors like CGPA, Internships, projects, etc. Change in the mindset of the millennial generation also contributes to ups and down in placement as the young generation is much into cloud Nine  than to owe a placement. Predicting the right questions for the placement is important for aspiring engineers in the corporate business. This makes it very important to come up with proper and smart technique to estimate the true prediction of the placement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhlNrfRasTmn"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5k_BnsbAbtD"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb7u6oKHsYD8"
      },
      "source": [
        "### Problem Statement\n",
        "\n",
        "\n",
        "You are willing to get your placement stats. You are not sure about the placement of yours and want to estimate your placement stats. You are provided with the dataset and need to make a prediction model which will help you to get a good estimate of your placement prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej0iNrOfw5mO"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywFr5pfow8Gc"
      },
      "source": [
        "### Data Description\n",
        "\n",
        "The **placement** dataset contains the prices and other attributes. There are $2967$ rows and $18$ attributes (features) with a target column (Age).\n",
        "\n",
        "Following are the features:  \n",
        "\n",
        "|Column|Description|\n",
        "|---:|\n",
        "Age\n",
        "Internships\n",
        "CGPA\n",
        "HistoryOfBacklogs\n",
        "teamWorking\n",
        "problemSolvingskills\n",
        "techSkillsLevel\n",
        "comSkillsLevel\n",
        "resumeLevel\n",
        "projectsNo\n",
        "easyProjects\n",
        "mediumProjects\n",
        "hardProjects\n",
        "advancedProjects\n",
        "personalityLevel\n",
        "winnerNo\n",
        "runnerNo\n",
        "participantNo\n",
        "  **Dataset Link:**  https://docs.google.com/spreadsheets/d/e/2PACX-1vSVwkDCMjC3YqMd3-aGNIB5gGrUhguSyWGTt6G5_mBuDZ6UcwsCDPRUyLnTVBtp4l8bksEJIXHj0qWL/pub?output=csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3-VjFOyqdvo"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iZ9tHdX647b"
      },
      "source": [
        "### Things To Do\n",
        "\n",
        "1. Explore the placement dataset by creating the following plots:\n",
        "   - Box plots between each categorical feature and the `word`.\n",
        "   - Scatter plots between the numerical features and the `words`.\n",
        "   \n",
        "2. Convert categorical attributes into numerical attributes using feature encoding.\n",
        "\n",
        "3. Build a linear regression model by selecting the most relevant features to predict the Age of houses.\n",
        "\n",
        "4. Evaluate the linear regression model by calculating the parameters such as coefficient of determination, MAE, MSE, RMSE, mean of residuals and by checking for homoscedasticity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4fE-t4Rr2CT"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0IW5qmC2Aaa"
      },
      "source": [
        "#### 1. Import Modules and Load Dataset\n",
        "\n",
        "**Dataset Link:** https://docs.google.com/spreadsheets/d/e/2PACX-1vSVwkDCMjC3YqMd3-aGNIB5gGrUhguSyWGTt6G5_mBuDZ6UcwsCDPRUyLnTVBtp4l8bksEJIXHj0qWL/pub?output=csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NKi_-YIxTcL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "fab5897e-fe98-429c-efbb-126b7e46fd56"
      },
      "source": [
        "# Import the required modules and load the dataset.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "df=pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\n",
        "df\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ad01752d8445>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             handle = _BytesZipFile(\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcompression_args\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, archive_name, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;31m# Union[str, PathLike[str]], ReadBuffer[bytes], WriteBuffer[bytes]]\";\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;31m# expected \"Union[Union[str, PathLike[str]], IO[bytes]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minfer_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IXJUhvx1Omc"
      },
      "source": [
        "# Get the information on DataFrame.\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB5wwgC1fO7Q"
      },
      "source": [
        "# Check if there are any NULL values.\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(df.columns.values)\n",
        "features.remove('Age')\n",
        "features"
      ],
      "metadata": {
        "id": "cW--hwFI7NuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCfhAcHAYvS4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTMp-43z7FQY"
      },
      "source": [
        "#### 2. Exploratory Data Analysis\n",
        "\n",
        "We need to predict the value of `price` variable, using other variables. Thus, `price` is the target or dependent variable and other columns except `price` are the features or the independent variables.\n",
        "\n",
        "Perform the following tasks:\n",
        "\n",
        "- Create Box plots between each **categorical** variable and the target variable `price` to sense the distribution of values.\n",
        "\n",
        "- Create the Scatter plots between each **numerical** variable and the target variable `price`. Determine which variable(s) shows linear relationship with the target variable `price`.\n",
        "\n",
        "- Create a normal distribution curve for the `price`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE095lJ7mTE6"
      },
      "source": [
        "# Check categorical attributes\n",
        "from sklearn.model_selection import train_test_split\n",
        "X=df[features]\n",
        "y=df['Age']\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33,random_state=29)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiF5b2D1yKDw"
      },
      "source": [
        "# Boxplot for 'Age' vs 'techSkillsLevel'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='Age', y='techSkillsLevel', data=df )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weHLdEjnyaE2"
      },
      "source": [
        "# Boxplot for 'teamWorking' vs 'comSkillsLevel'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='teamWorking', y='comSkillsLevel', data=df )\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p09SUbbhympd"
      },
      "source": [
        "# Boxplot for 'problemSolvingskills' vs 'techSkillsLevel'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='problemSolvingskills', y='techSkillsLevel', data=df )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kth0hysho8Zc"
      },
      "source": [
        "# Boxplot for 'winnerNo' vs 'techSkillsLevel'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='winnerNo', y='techSkillsLevel', data=df )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We94X-Dfo9BZ"
      },
      "source": [
        "# Boxplot for 'CGPA' vs 'techSkillsLevel'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='CGPA', y='techSkillsLevel', data=df )\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot for 'CGPA' vs 'problemSolvingskills'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='CGPA', y='problemSolvingskills', data=df )\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LJJOp4AV9X2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfa6bSKIo98Y"
      },
      "source": [
        "# Boxplot for 'advancedProjects' vs 'techSkillsLevel'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='advancedProjects', y='techSkillsLevel', data=df )\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot for 'problemSolvingskills' vs 'hardProjects'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='problemSolvingskills', y='hardProjects', data=df )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0FyErIc59jTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1OlbcvXjy4s"
      },
      "source": [
        "# Boxplot for 'resumeLevel' vs 'techSkillsLevel'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='resumeLevel', y='techSkillsLevel', data=df )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot for 'techSkillsLevel' vs 'participantNo'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='techSkillsLevel', y='participantNo', data=df )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dNIKp5Dv6xmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot for 'techSkillsLevel' vs 'runnerNo'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='techSkillsLevel', y='runnerNo', data=df )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dvEIW9Mj7mZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot for 'advancedProjects' vs 'winnerNo'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='advancedProjects', y='winnerNo', data=df )\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vSJQQM5972IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot for 'advancedProjects' vs 'runnerNo'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='advancedProjects', y='runnerNo', data=df )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ug7DUbCU9BdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot for 'techSkillsLevel' vs 'winnerNo'\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='techSkillsLevel', y='winnerNo', data=df )\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cWFWSxDJ8Hel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnJ_Yv9MzSn8"
      },
      "source": [
        "#  scatter plot with 'mediumProjects' on X-axis and 'techSkillsLevel' on Y-axis\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.scatter(x='mediumProjects', y='techSkillsLevel', data=df )\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scatter plot with 'advancedProjects' on X-axis and 'winnerNo' on Y-axis\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.scatter(x='advancedProjects', y='winnerNo', data=df )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rIrt8gxE6Knp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is7gd_Z1p4y7"
      },
      "source": [
        "#  scatter plot with 'Age' on X-axis and 'personalityLevel' on Y-axis\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.scatter(x='Age', y='personalityLevel', data=df )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nawvemNp5jO"
      },
      "source": [
        "# scatter plot with 'easyProjects' on X-axis and 'Internships' on Y-axis\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.scatter(x='easyProjects', y='Internships', data=df )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDfLIRf0p6b1"
      },
      "source": [
        "# Create scatter plot with 'CGPA' on X-axis and 'HistoryOfBacklogs' on Y-axis\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.scatter(x='CGPA', y='HistoryOfBacklogs', data=df )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIpsz4Gd5M-e"
      },
      "source": [
        "# Create a normal distribution curve for the 'Internships'.\n",
        "plt.style.use('ggplot')\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.title('normal distribution curve for the Internships')\n",
        "sns.distplot(df['Internships'],bins='sturges',hist=False)\n",
        "plt.grid()\n",
        "plt.show()\n",
        "# Create a probablity density function for plotting the normal distribution\n",
        "\n",
        "\n",
        "# Plot the normal distribution curve using plt.scatter()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "features = list(df.columns.values)\n",
        "features.remove('Age')\n",
        "features"
      ],
      "metadata": {
        "id": "xyWZHgequPnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def myfunc(n):\n",
        "  return len(n)\n",
        "\n",
        "x = map(myfunc, ('r2_score', 0,1,3,20))\n",
        "\n"
      ],
      "metadata": {
        "id": "7hkn-xKjzZ-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Create data frames for the features and target again and also split them into the train and test sets.\n",
        "X = df[features]\n",
        "y = df['Age']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42) # Test set will have 33% of the values.\n",
        "\n",
        "# Add a constant to get an intercept\n",
        "X_train_sm = sm.add_constant(X_train)\n",
        "\n",
        "# Fit the regression line using 'OLS'\n",
        "lr = sm.OLS(y_train, X_train_sm).fit()\n",
        "\n",
        "# Print the parameters, i.e. the intercept and the slope of the regression line fitted\n",
        "lr.params\n"
      ],
      "metadata": {
        "id": "KmwFRHqeuLA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.summary())"
      ],
      "metadata": {
        "id": "KJwiRDfUveSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnYUk03JZHNW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV_89Nj7134T"
      },
      "source": [
        "#### 3. Feature encoding\n",
        "\n",
        "Perform feature encoding using `map()` function and one-hot encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOCUEcX8uRqy"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPA5gDelbIhQ"
      },
      "source": [
        "#### 4. Model Building and Evaluation\n",
        "\n",
        "Build a multiple linear regression model using the `statsmodels.api` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQzZoKiQMsLe"
      },
      "source": [
        "# Split the 'df' Dataframe into the train and test sets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size = 0.3, random_state = 42)\n",
        "features = list(df.columns)\n",
        "features.remove('Age')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separate data-frames for the feature and target variables for both the train and test sets.\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['Age']\n",
        "X_test = test_df[features]\n",
        "y_test = test_df['Age']\n",
        "\n",
        "X_train[X_train.columns[:16]] = X_train[X_train.columns[:16]]\n",
        "X_test[X_test.columns[:16]] = X_test[X_test.columns[:16]]"
      ],
      "metadata": {
        "id": "F37BjQrfvMFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmVNQIXoM_e7"
      },
      "source": [
        "# Build a linear regression model using all the features to predict placement.\n",
        "import statsmodels.api as sm\n",
        "\n",
        "X_train_sm = sm.add_constant(X_train)\n",
        "lin_reg = sm.OLS(y_train, X_train_sm).fit()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cy5mc--BvVv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTRC2EzPNES8"
      },
      "source": [
        "# calculate N and p-values.\n",
        "num_rows = X_train.shape[0] # Number of rows or instances\n",
        "num_predictors = X_train.shape[1] # Number of columns or feature (or independent) variables\n",
        "print(\"Number of rows (N):\", num_rows)\n",
        "print(\"Number of predictors (p):\", num_predictors)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_sq_model(X, y_actual):\n",
        "    y_pred = lin_reg.predict(X)\n",
        "    sq_model = (y_pred - y_actual.mean()) ** 2\n",
        "    msm = sq_model.sum() / (num_predictors - 1)\n",
        "    return msm\n",
        "\n",
        "def mean_sq_error(X, y_actual):\n",
        "    y_pred = lin_reg.predict(X)\n",
        "    sq_error = (y_actual - y_pred) ** 2\n",
        "    mse = sq_error.sum() / (num_rows - num_predictors)\n",
        "    return mse"
      ],
      "metadata": {
        "id": "Ea4fgShn-e6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5oVTSm2NI0N"
      },
      "source": [
        "# Calculate the p-value\n",
        "f_statistic=mean_sq_model(X_train_sm,y_train)/mean_sq_error(X_train_sm,y_train)\n",
        "f_statistic\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "pvalue = (2 * (1 - norm.cdf(abs(f_statistic))))\n",
        "pvalue"
      ],
      "metadata": {
        "id": "qEdFcKWA0LWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uN86XNjohcgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Find adjusted r squared\n",
        "num_rows = X_train.shape[0] # Number of rows or instances\n",
        "num_predictors = X_train.shape[1] # Number of columns or feature (or independent) variables\n",
        "r2_score = lin_reg.rsquared # R-squared (or coefficient of determination) value\n",
        "adj_r2_score = 1 - ((1 - r2_score) * (num_rows - 1))/(num_rows - num_predictors - 1) # Adjusted R-squared calculation\n",
        "adj_r2_score"
      ],
      "metadata": {
        "id": "25-of2kKhdZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g5bWR7KevKp"
      },
      "source": [
        "**Q:** What is the  adjusted r-squared value?\n",
        "\n",
        "**A:** -0.0009\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGiJbicSY0cB"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdISoNS3dXv7"
      },
      "source": [
        "#### 5. Model Evaluation\n",
        "\n",
        "Build a multiple linear regression model  using `sklearn` module. Also, evaluate the model by calculating $R^2$, MSE, RMSE, and MAE values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UasyrqoReltr"
      },
      "source": [
        "# Build multiple linear regression model using all the features\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "X = df[features]\n",
        "y = df['Age']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
        "\n",
        "\n",
        "y_train_reshaped = y_train.values.reshape(-1, 1)\n",
        "y_test_reshaped = y_test.values.reshape(-1, 1)\n",
        "\n",
        "\n",
        "sklearn_lin_reg = LinearRegression()\n",
        "sklearn_lin_reg.fit(X_train, y_train_reshaped)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nConstant\".ljust(15, \" \"), f\"{sklearn_lin_reg.intercept_[0]:.6f}\")\n",
        "\n",
        "\n",
        "for item in list(zip(X.columns.values, sklearn_lin_reg.coef_[0])):\n",
        "  print(f\"{item[0]}\".ljust(15, \" \"), f\"{item[1]:.6f}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_Jn8jYZe0AJ"
      },
      "source": [
        "# Evaluate the linear regression model using the 'r2_score', 'mean_squared_error' & 'mean_absolute_error' functions of the 'sklearn' module.\n",
        "from sklearn.metrics import r2_score, mean_squared_error , mean_absolute_error,mean_squared_log_error\n",
        "y_train_predict = sklearn_lin_reg.predict(X_train)\n",
        "y_test_predict = sklearn_lin_reg.predict(X_test)\n",
        "\n",
        "r2_score=r2_score(y_train,y_train_predict)\n",
        "mean_squared_error=mean_squared_error(y_train,y_train_predict)\n",
        "mean_absolute_error=mean_absolute_error(y_train,y_train_predict)\n",
        "print(r2_score,mean_squared_error,mean_absolute_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQjDiF7TY3NN"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYr8UQBp6AlS"
      },
      "source": [
        "#### 6. Recursive Feature Elimination\n",
        "\n",
        "Find out the best features out of all features using RFE and evaluate the model again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I4LSmb0oew9"
      },
      "source": [
        "#  a Python dictionary storing the moderately to highly correlated features with techSkillsLevel and the corresponding correlation values.\n",
        "#  correlation threshold to be 0.2\n",
        "major_features = {}\n",
        "for f in features:\n",
        "  corr_coef = np.corrcoef(df['techSkillsLevel'], df[f])[0, 1]\n",
        "  if (corr_coef >= 0.2) or (corr_coef <= -0.2):\n",
        "    major_features[f] = corr_coef\n",
        "\n",
        "print(\"Number of features moderately to highly correlated with techSkillsLevel =\", len(major_features), \"\\n\")\n",
        "major_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8SxpFJh7lFq"
      },
      "source": [
        "#Build multiple linear regression model using all the features selected after RFE\n",
        "#Split the DataFrame into the train and test sets such that test set has 33% of the values.\n",
        "#Split the DataFrame into the train and test sets such that test set has 33% of the values.\n",
        "\n",
        "X = df[features]\n",
        "y = df['Age']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
        "\n",
        "\n",
        "y_train_reshaped = y_train.values.reshape(-1, 1)\n",
        "y_test_reshaped = y_test.values.reshape(-1, 1)\n",
        "\n",
        "# Build linear regression model using the 'sklearn.linear_model' module.\n",
        "\n",
        "sklearn_lin_reg = LinearRegression()\n",
        "sklearn_lin_reg.fit(X_train, y_train_reshaped)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nConstant\".ljust(15, \" \"), f\"{sklearn_lin_reg.intercept_[0]:.6f}\")\n",
        "\n",
        "# Print the names of the features along with the values of their corresponding coefficients.\n",
        "\n",
        "for item in list(zip(X.columns.values, sklearn_lin_reg.coef_[0])):\n",
        "  print(f\"{item[0]}\".ljust(15, \" \"), f\"{item[1]:.6f}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TL6w_uf7lDH"
      },
      "source": [
        "# Evaluate the linear regression model using the 'r2_score', 'mean_squared_error' & 'mean_absolute_error' functions of the 'sklearn' module.\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "y_train_pred = sklearn_lin_reg.predict(X_train)\n",
        "y_test_pred = sklearn_lin_reg.predict(X_test)\n",
        "\n",
        "print(f\"Train Set\\n{'-' * 50}\")\n",
        "print(f\"R-squared: {r2_score(y_train_reshaped, y_train_pred):.3f}\")\n",
        "print(f\"Mean Squared Error: {mean_squared_error(y_train_reshaped, y_train_pred):.3f}\")\n",
        "print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error(y_train_reshaped, y_train_pred)):.3f}\")\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error(y_train_reshaped, y_train_pred):.3f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ctl1HKaY6Uy"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8Y3O5R88IrL"
      },
      "source": [
        "#### 7. Residual (Error) Analysis\n",
        "\n",
        "Perform residual analysis to check if the residuals (errors) are normally distributed or not. For this, plot the  histogram of the residuals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYF-WdWn8QmU"
      },
      "source": [
        "# a histogram for the errors obtained in the predicted values for the train set.\n",
        "train_error=y_train_pred\n",
        "plt.figure(figsize=(15,6))\n",
        "sns.distplot(train_error,bins='sturges')\n",
        "plt.axvline(x=np.mean(train_error),color='purple')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJv_gr1N8T5U"
      },
      "source": [
        "#  a histogram for the errors obtained in the predicted values for the test set.\n",
        "test_error=y_test_pred\n",
        "plt.figure(figsize=(15,6))\n",
        "sns.distplot(train_error,bins='sturges')\n",
        "plt.axvline(x=np.mean(train_error),color='purple')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-uMjpUMY932"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMZN8NeX8rde"
      },
      "source": [
        " 8.  Homoscedasticity\n",
        "\n",
        "We can Check for Homoscedasticity (constant variance) by creating a scatter plot between the errors and the target variable. Determine whether there is some kind of relationship between the error and the target variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uptEDE578wjm"
      },
      "source": [
        "#  a scatter plot between the errors and the dependent variable for the train set.\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.scatter(y_train,train_error)\n",
        "plt.axhline(y=np.mean(train_error),color='red')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydTo7_b5JMpu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS4vTi_EAsC5"
      },
      "source": [
        "---"
      ]
    }
  ]
}